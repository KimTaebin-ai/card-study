{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31012,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "id": "c081601b291d2150",
   "cell_type": "code",
   "source": "import pandas as pd\nimport numpy as np\nimport glob",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 메모리 사용량 확인 및 정리",
   "id": "111f0de741b54e73"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def check_memory_usage():\n",
    "    memory_usage = pd.DataFrame(columns=['Name', 'Memory Usage (MB)'])\n",
    "    for var_name in dir():\n",
    "        if var_name.startswith('_') or var_name in ['memory_usage', 'check_memory_usage', 'gc', 'pd', 'np']:\n",
    "            continue\n",
    "        var = globals()[var_name]\n",
    "        if isinstance(var, pd.DataFrame):\n",
    "            memory_mb = var.memory_usage(deep=True).sum() / 1024 / 1024\n",
    "            temp_df = pd.DataFrame([[var_name, f\"{memory_mb:.2f}\"]], columns=['Name', 'Memory Usage (MB)'])\n",
    "            memory_usage = pd.concat([memory_usage, temp_df], ignore_index=True)\n",
    "\n",
    "    memory_usage = memory_usage.sort_values(by='Memory Usage (MB)', ascending=False).reset_index(drop=True)\n",
    "    print(memory_usage.head(10))\n",
    "    total_memory = float(memory_usage['Memory Usage (MB)'].str.replace(',', '').astype(float).sum())\n",
    "    print(f\"Total Memory Usage: {total_memory:.2f} MB\")"
   ],
   "id": "7c7e76d606dfddf3"
  },
  {
   "id": "8a080f97ef8a86c5",
   "cell_type": "markdown",
   "source": "# 파일 불러오기",
   "metadata": {}
  },
  {
   "id": "cfcc38269c6570cf",
   "cell_type": "code",
   "source": "def load_data(data_type):\n    dfs = {}\n    base_path = f\"/kaggle/input/credit-card-segment/open/{data_type}\"\n    categories = {\n        \"customer\": \"1\",\n        \"credit\": \"2\",\n        \"sales\": \"3\",\n        \"billing\": \"4\",\n        \"balance\": \"5\",\n        \"channel\": \"6\",\n        \"marketing\": \"7\",\n        \"performance\": \"8\"\n    }\n    for name, prefix in categories.items():\n        path =  f\"{base_path}/{prefix}.*/*.parquet\"\n        files = sorted(glob.glob(path))\n        if not files:\n            print(f\"No parquet files found in {path}\")\n            continue\n        dfs[name] = pd.concat([pd.read_parquet(f) for f in files], ignore_index=True)\n        print(f\"{name} Loaded {dfs[name].shape} parquet files\")\n    return dfs",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:41:08.139445Z",
     "start_time": "2025-04-25T17:41:08.136725Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "57d6ec6c4c3b23e0",
   "cell_type": "code",
   "source": "train_df = load_data(\"train\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:41:18.284134Z",
     "start_time": "2025-04-25T17:41:08.215364Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "38d8a41bb623ad27",
   "cell_type": "code",
   "source": "test_df = load_data(\"test\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:41:20.518585Z",
     "start_time": "2025-04-25T17:41:18.307464Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "e30466603f24cff6",
   "cell_type": "code",
   "source": "customer_train_df = train_df[\"customer\"]\ncredit_train_df   = train_df[\"credit\"]\nsales_train_df    = train_df[\"sales\"]\nbilling_train_df  = train_df[\"billing\"]\nbalance_train_df  = train_df[\"balance\"]\nchannel_train_df  = train_df[\"channel\"]\nmarketing_train_df= train_df[\"marketing\"]\nperformance_train_df = train_df[\"performance\"]",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:41:20.543746Z",
     "start_time": "2025-04-25T17:41:20.541685Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "e707534ea7efc12f",
   "cell_type": "code",
   "source": "customer_test_df = test_df[\"customer\"]\ncredit_test_df   = test_df[\"credit\"]\nsales_test_df    = test_df[\"sales\"]\nbilling_test_df  = test_df[\"billing\"]\nbalance_test_df  = test_df[\"balance\"]\nchannel_test_df  = test_df[\"channel\"]\nmarketing_test_df= test_df[\"marketing\"]\nperformance_test_df = test_df[\"performance\"]",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:41:20.587524Z",
     "start_time": "2025-04-25T17:41:20.585403Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "5d3b12be3401e4fa",
   "cell_type": "code",
   "source": "def check_memory_usage(df):\n    memory_usage = df.memory_usage(deep=True).sum() / 1024**2  # MB 단위로 변환\n    print(f\"메모리 사용량: {memory_usage:.2f} MB\")\n    return memory_usage",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:41:20.592095Z",
     "start_time": "2025-04-25T17:41:20.590346Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "b4f2e0de6cb2a949",
   "cell_type": "code",
   "source": "print(\"메모리 사용량 확인:\")\ncheck_memory_usage(customer_train_df)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:41:23.283135Z",
     "start_time": "2025-04-25T17:41:20.625080Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "ab3202dc107b16c0",
   "cell_type": "code",
   "source": "import gc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:41:23.321010Z",
     "start_time": "2025-04-25T17:41:23.318659Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "5f870417ab4c5e00",
   "cell_type": "code",
   "source": "import re",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:41:23.355532Z",
     "start_time": "2025-04-25T17:41:23.353653Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "6a9f0c34dc9f3b96",
   "cell_type": "markdown",
   "source": [
    "# 전처리 함수들\n",
    "1. '개, 대, 회, 이상, 회이상, 개이상, 대이상, 대 이상, 회 이상'로 끝나는 문자열에서 숫자만 추출\n",
    "2. '', 'none', 'null', 'nan', 'NaN' 이 문자열로 들어왔을 때 처리, 10101, -999999, -99, 999, 99999999 값 0 처리\n",
    "3. unique 값이 1개인 컬럼 drop\n",
    "4. IQR 방식으로 이상치 탐색 후 NaN 으로 대치 (날짜 형태의 컬럼은 0으로 처리)\n",
    "5. 날짜형 데이터의 추가적인 결측치가 있을 경우 0처리\n",
    "6. 각 컬럼별 결측치의 비율에 따라 평균값, 중앙값, 최빈값, drop등으로 처리"
   ],
   "metadata": {}
  },
  {
   "id": "b1dfecf8ef1f556f",
   "cell_type": "markdown",
   "source": "## 문자열 -> 수치형으로 파싱\n\n'개, 대, 회, 이상, 회이상, 개이상, 대이상'로 끝나는 문자열에서 숫자만 추출\n",
   "metadata": {}
  },
  {
   "id": "f68e83ebe4da9969",
   "cell_type": "code",
   "source": "def clean_units_from_dataframe(df):\n    # 데이터프레임 복사본 생성\n    df_cleaned = df.copy()\n    object_columns = df_cleaned.select_dtypes(include=['object']).columns\n    # 각 object 컬럼 처리\n    for col in object_columns:\n        # 문자열인 경우에만 처리\n        mask = df_cleaned[col].apply(lambda x: isinstance(x, str))\n\n        if mask.any():  # 문자열이 하나 이상 있는 경우만 처리\n            unit_pattern = r'\\d+\\s*(개|대|회|이상|회이상|개이상|대이상|회 이상|일 이상)$'\n            # re.search를 직접 적용하여 경고 피하기\n            unit_mask = df_cleaned.loc[mask, col].apply(lambda x: bool(re.search(unit_pattern, x)))\n\n            # 단위가 있는 값만 처리\n            if unit_mask.any():\n                # 숫자 추출하기 위한 패턴\n                number_pattern = r'(\\d+)\\s*(개|대|회|이상|회이상|개이상|대이상|회 이상|일 이상)$'\n                # 숫자 부분만 추출\n                extracted_numbers = df_cleaned.loc[mask, col].str.extract(number_pattern)[0]\n                # 추출된 숫자를 새로운 값으로 사용 (숫자로 변환)\n                df_cleaned.loc[mask & unit_mask, col] = pd.to_numeric(\n                    extracted_numbers.loc[unit_mask], errors='coerce')\n    return df_cleaned",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:41:23.420888Z",
     "start_time": "2025-04-25T17:41:23.417725Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "d832e6c42eac7b69",
   "cell_type": "code",
   "source": "customer_train_df = clean_units_from_dataframe(customer_train_df)\ncredit_train_df   = clean_units_from_dataframe(credit_train_df)\nsales_train_df    = clean_units_from_dataframe(sales_train_df)\nbilling_train_df  = clean_units_from_dataframe(billing_train_df)\nbalance_train_df  = clean_units_from_dataframe(balance_train_df)\nchannel_train_df  = clean_units_from_dataframe(channel_train_df)\nmarketing_train_df= clean_units_from_dataframe(marketing_train_df)\nperformance_train_df = clean_units_from_dataframe(performance_train_df)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:43:38.291426Z",
     "start_time": "2025-04-25T17:41:23.423241Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "45e89152286a183f",
   "cell_type": "code",
   "source": "customer_test_df     = clean_units_from_dataframe(customer_test_df)\ncredit_test_df       = clean_units_from_dataframe(credit_test_df)\nsales_test_df        = clean_units_from_dataframe(sales_test_df)\nbilling_test_df      = clean_units_from_dataframe(billing_test_df)\nbalance_test_df      = clean_units_from_dataframe(balance_test_df)\nchannel_test_df      = clean_units_from_dataframe(channel_test_df)\nmarketing_test_df    = clean_units_from_dataframe(marketing_test_df)\nperformance_test_df  = clean_units_from_dataframe(performance_test_df)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:44:11.645799Z",
     "start_time": "2025-04-25T17:43:38.382527Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "c00d8be25eef84df",
   "cell_type": "code",
   "source": "marketing_test_df.head()",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:44:11.705217Z",
     "start_time": "2025-04-25T17:44:11.693852Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "93667b12c8025790",
   "cell_type": "markdown",
   "source": "## 결측치 수기 처리\n\n'', 'none', 'null', 'nan', 'NaN' 이 문자열로 들어왔을 때 처리, 10101, -999999, -99, 999, 99999999 값 0 처리",
   "metadata": {}
  },
  {
   "id": "697777ef6a47705f",
   "cell_type": "code",
   "source": "def is_special_null(df):\n    df_copy = df.copy()\n\n    # 문자열 컬럼 처리 (벡터화된 방식)\n    for col in df_copy.select_dtypes(include=['object']).columns:\n        # 문자열 컬럼에서 빈 문자열, 'none', 'null', 'nan' 찾기\n        mask = df_copy[col].astype(str).str.lower().isin(['', 'none', 'null', 'nan', 'NaN'])\n        df_copy.loc[mask, col] = np.nan  # NaN으로 변경\n\n    # 숫자 컬럼 처리\n    for col in df_copy.select_dtypes(include=['int64', 'float64']).columns:\n        # 특정 숫자값 찾기\n        mask = df_copy[col].isin([10101, -999999, -99, 999, 99999999])\n        df_copy.loc[mask, col] = np.nan  # NaN으로 변경\n    return df_copy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:44:11.771388Z",
     "start_time": "2025-04-25T17:44:11.768433Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "347ac39ee79626c6",
   "cell_type": "code",
   "source": "customer_train_df = is_special_null(customer_train_df)\ncredit_train_df   = is_special_null(credit_train_df)\nsales_train_df    = is_special_null(sales_train_df)\nbilling_train_df  = is_special_null(billing_train_df)\nbalance_train_df  = is_special_null(balance_train_df)\nchannel_train_df  = is_special_null(channel_train_df)\nmarketing_train_df= is_special_null(marketing_train_df)\nperformance_train_df = is_special_null(performance_train_df)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:45:06.489166Z",
     "start_time": "2025-04-25T17:44:11.917178Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "94d3f5c1549be2fc",
   "cell_type": "code",
   "source": "customer_test_df     = is_special_null(customer_test_df)\ncredit_test_df       = is_special_null(credit_test_df)\nsales_test_df        = is_special_null(sales_test_df)\nbilling_test_df      = is_special_null(billing_test_df)\nbalance_test_df      = is_special_null(balance_test_df)\nchannel_test_df      = is_special_null(channel_test_df)\nmarketing_test_df    = is_special_null(marketing_test_df)\nperformance_test_df  = is_special_null(performance_test_df)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:45:17.085982Z",
     "start_time": "2025-04-25T17:45:06.500840Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "1930bdceb9cfe932",
   "cell_type": "code",
   "source": "marketing_test_df.head()",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:45:17.143061Z",
     "start_time": "2025-04-25T17:45:17.133569Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "760c21b4efb1625f",
   "cell_type": "markdown",
   "source": "## 컬럼별 데이터 형태가 1개밖에 없는 경우 drop\n\nunique 값이 1개인 컬럼 drop\n",
   "metadata": {}
  },
  {
   "id": "e22c8245fa830da8",
   "cell_type": "code",
   "source": "def remove_single_value_columns(df):\n    single_value_cols = []\n    for col in df.columns:\n        if df[col].nunique() == 1:\n            single_value_cols.append(col)\n\n    if single_value_cols:\n        print(f\"제거할 컬럼 (유니크 값 1개): {single_value_cols}\")\n        df = df.drop(columns=single_value_cols)\n    else:\n        print(\"유니크 값이 1개인 컬럼이 없습니다.\")\n\n    return df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:45:17.210865Z",
     "start_time": "2025-04-25T17:45:17.208832Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "afa5636c7e05e726",
   "cell_type": "code",
   "source": "customer_train_df = remove_single_value_columns(customer_train_df)\ncredit_train_df   = remove_single_value_columns(credit_train_df)\nsales_train_df    = remove_single_value_columns(sales_train_df)\nbilling_train_df  = remove_single_value_columns(billing_train_df)\nbalance_train_df  = remove_single_value_columns(balance_train_df)\nchannel_train_df  = remove_single_value_columns(channel_train_df)\nmarketing_train_df= remove_single_value_columns(marketing_train_df)\nperformance_train_df = remove_single_value_columns(performance_train_df)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:45:37.515842Z",
     "start_time": "2025-04-25T17:45:17.214631Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "560a2b11d7e3768d",
   "cell_type": "code",
   "source": "customer_test_df     = remove_single_value_columns(customer_test_df)\ncredit_test_df       = remove_single_value_columns(credit_test_df)\nsales_test_df        = remove_single_value_columns(sales_test_df)\nbilling_test_df      = remove_single_value_columns(billing_test_df)\nbalance_test_df      = remove_single_value_columns(balance_test_df)\nchannel_test_df      = remove_single_value_columns(channel_test_df)\nmarketing_test_df    = remove_single_value_columns(marketing_test_df)\nperformance_test_df  = remove_single_value_columns(performance_test_df)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:45:41.631972Z",
     "start_time": "2025-04-25T17:45:37.542222Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "2560dde5727a476e",
   "cell_type": "code",
   "source": "customer_date_columns = [\"입회일자_신용\", \"최종유효년월_신용_이용가능\", \"최종유효년월_신용_이용\", \"최종카드발급일자\"]\nsales_date_columns = [\"최종이용일자_기본\", \"최종이용일자_신판\", \"최종이용일자_CA\", \"최종이용일자_카드론\", \"최종이용일자_체크\", \"최종이용일자_일시불\", \"최종이용일자_할부\", \"최종카드론_대출일자\"]\n\n# 입회일자_신용, 최종유효년월_신용_이용가능, 최종유효년월_신용_이용, 최종카드발급일자\n#\n# 최종이용일자_기본, 최종이용일자_신판, 최종이용일자_CA, 최종이용일자_카드론, 최종이용일자_체크, 최종이용일자_일시불, 최종이용일자_할부, 최종카드론_대출일자\n#\n#\n#\n#",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:45:41.643778Z",
     "start_time": "2025-04-25T17:45:41.638299Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "5596ddf843b56abb",
   "cell_type": "markdown",
   "source": "## 이상치 처리\n\nIQR 방식으로 이상치 탐색 후 NaN 으로 대치 (날짜 형태의 컬럼은 0으로 처리)\n\n날짜형 데이터의 추가적인 결측치가 있을 경우 0처리",
   "metadata": {}
  },
  {
   "id": "df70001ce7779e75",
   "cell_type": "code",
   "source": "def handle_outliers_with_iqr(df, date_columns=None):\n    df_copy = df.copy()\n\n    if date_columns is None:\n        date_columns = []\n\n    # 모든 수치형 컬럼 선택\n    numeric_cols = df_copy.select_dtypes(include=['int64', 'float64']).columns\n\n    # 각 수치형 컬럼 처리\n    for col in numeric_cols:\n        # 결측치가 아닌 값으로만 IQR 계산\n        valid_data = df_copy[col].dropna()\n\n        if len(valid_data) > 0:  # 유효한 데이터가 있는 경우만 처리\n            Q1 = valid_data.quantile(0.25)\n            Q3 = valid_data.quantile(0.75)\n            IQR = Q3 - Q1\n\n            # 이상치 경계 계산\n            lower_bound = Q1 - 1.5 * IQR\n            upper_bound = Q3 + 1.5 * IQR\n\n            # 이상치 찾기\n            mask_lower = df_copy[col] < lower_bound\n            mask_upper = df_copy[col] > upper_bound\n\n            # 이상치 개수 출력\n            outliers_count = mask_lower.sum() + mask_upper.sum()\n            if outliers_count > 0:\n                print(f\"컬럼 '{col}': {outliers_count}개의 이상치 발견 (하한값: {lower_bound}, 상한값: {upper_bound})\")\n\n            # 이상치 처리 - date_columns에 포함된 컬럼이면 0으로, 아니면 NaN으로\n            if col in date_columns:\n                df_copy.loc[mask_lower | mask_upper, col] = 0\n                if outliers_count > 0:\n                    print(f\"  -> 날짜 컬럼으로 간주하여 이상치를 0으로 대체\")\n            else:\n                df_copy.loc[mask_lower | mask_upper, col] = np.nan\n                if outliers_count > 0:\n                    print(f\"  -> 일반 컬럼으로 간주하여 이상치를 NaN으로 대체\")\n\n    return df_copy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:45:41.778958Z",
     "start_time": "2025-04-25T17:45:41.775394Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "50b67bcb79c573e1",
   "cell_type": "code",
   "source": "customer_train_df   = handle_outliers_with_iqr(customer_train_df, customer_date_columns)\ncredit_train_df      = handle_outliers_with_iqr(credit_train_df)\nsales_train_df      = handle_outliers_with_iqr(sales_train_df, sales_date_columns)\nbilling_train_df    = handle_outliers_with_iqr(billing_train_df)\nbalance_train_df    = handle_outliers_with_iqr(balance_train_df)\nchannel_train_df    = handle_outliers_with_iqr(channel_train_df)\nmarketing_train_df  = handle_outliers_with_iqr(marketing_train_df)\nperformance_train_df = handle_outliers_with_iqr(performance_train_df)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:46:35.487043Z",
     "start_time": "2025-04-25T17:45:41.784046Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "716b539329f54eb4",
   "cell_type": "code",
   "source": "customer_test_df     = handle_outliers_with_iqr(customer_test_df, customer_date_columns)\ncredit_test_df       = handle_outliers_with_iqr(credit_test_df)\nsales_test_df        = handle_outliers_with_iqr(sales_test_df, sales_date_columns)\nbilling_test_df      = handle_outliers_with_iqr(billing_test_df)\nbalance_test_df      = handle_outliers_with_iqr(balance_test_df)\nchannel_test_df      = handle_outliers_with_iqr(channel_test_df)\nmarketing_test_df    = handle_outliers_with_iqr(marketing_test_df)\nperformance_test_df  = handle_outliers_with_iqr(performance_test_df)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:46:47.647454Z",
     "start_time": "2025-04-25T17:46:35.531503Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "e4e8aaa00c019c14",
   "cell_type": "code",
   "source": "def handle_date_columns(df, date_cols):\n    for col in date_cols:\n        if col in df.columns:\n            missing_before = df[col].isnull().sum()\n            df[col] = df[col].fillna(0)\n            missing_after = df[col].isnull().sum()\n            print(f\"컬럼 '{col}'의 결측치: {missing_before} -> {missing_after}\")\n    return df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:46:47.727221Z",
     "start_time": "2025-04-25T17:46:47.724786Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "9f71410a3781a1c6",
   "cell_type": "code",
   "source": "customer_train_df = handle_date_columns(customer_train_df, customer_date_columns)\n\nsales_train_df = handle_date_columns(sales_train_df, sales_date_columns)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:46:47.883431Z",
     "start_time": "2025-04-25T17:46:47.768111Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "807adba14a68ed6f",
   "cell_type": "code",
   "source": "customer_test_df = handle_date_columns(customer_test_df, customer_date_columns)\n\nsales_test_df = handle_date_columns(sales_test_df, sales_date_columns)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:46:47.911359Z",
     "start_time": "2025-04-25T17:46:47.886929Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "3d861c6b477282e0",
   "cell_type": "markdown",
   "source": "## 결측치 처리\n\n각 컬럼별 결측치의 비율에 따라 평균값, 중앙값, 최빈값, drop등으로 처리",
   "metadata": {}
  },
  {
   "id": "a76462af12a7e42c",
   "cell_type": "code",
   "source": "def handle_missing_values(df):\n    df_copy = df.copy()\n\n    # 결측치가 있는 컬럼 찾기\n    columns_with_missing = [col for col in df_copy.columns if df_copy[col].isnull().sum() > 0]\n\n    for col in columns_with_missing:\n        missing_count = df_copy[col].isnull().sum()\n        missing_ratio = missing_count / len(df_copy)\n        print(f\"컬럼 '{col}'의 결측치: {missing_count}개 ({missing_ratio:.4f})\")\n\n        # 결측 비율에 따른 처리\n        if missing_ratio > 0.75:\n            # 75% 초과 결측: 컬럼 제거 고려\n            print(f\"  -> 결측치 비율이 75%를 초과합니다. 해당 컬럼 제거\")\n            df_copy = df_copy.drop(columns=[col])\n\n        elif missing_ratio > 0.5:\n            # 50~75% 결측: 컬럼 유지하되 결측치는 분포의 중심값으로 대체\n            if df_copy[col].dtype in ['int64', 'float64']:\n                # 수치형: 중앙값(median)으로 대체\n                median_val = df_copy[col].median()\n                df_copy[col] = df_copy[col].fillna(median_val)\n                print(f\"  -> 결측 비율이 높은 수치형 컬럼이므로 중앙값 {median_val}으로 대체\")\n            else:\n                # 범주형: 최빈값(mode)으로 대체\n                mode_val = df_copy[col].mode()[0] if not df_copy[col].mode().empty else \"unknown\"\n                df_copy[col] = df_copy[col].fillna(mode_val)\n                print(f\"  -> 결측 비율이 높은 범주형 컬럼이므로 최빈값 '{mode_val}'으로 대체\")\n\n        elif missing_ratio > 0.3:\n            # 30~50% 결측: 수치형은 평균/분포 기반, 범주형은 최빈값 대체\n            if df_copy[col].dtype in ['int64', 'float64']:\n                # 왜도(skewness) 확인하여 처리\n                skew = df_copy[col].skew()\n                if abs(skew) > 1:  # 비대칭 분포인 경우\n                    median_val = df_copy[col].median()\n                    df_copy[col] = df_copy[col].fillna(median_val)\n                    print(f\"  -> 분포가 비대칭(skew={skew:.2f})이므로 중앙값 {median_val}으로 대체\")\n                else:  # 대칭 분포인 경우\n                    mean_val = df_copy[col].mean()\n                    df_copy[col] = df_copy[col].fillna(mean_val)\n                    print(f\"  -> 분포가 대칭(skew={skew:.2f})이므로 평균값 {mean_val}으로 대체\")\n            else:\n                # 범주형: 최빈값으로 대체\n                mode_val = df_copy[col].mode()[0] if not df_copy[col].mode().empty else \"unknown\"\n                df_copy[col] = df_copy[col].fillna(mode_val)\n                print(f\"  -> 범주형 컬럼이므로 최빈값 '{mode_val}'으로 대체\")\n\n        else:\n            # 30% 이하 결측: 일반적인 대체 방법 적용\n            if df_copy[col].dtype in ['int64', 'float64']:\n                # 왜도 확인\n                skew = df_copy[col].skew()\n                if abs(skew) > 1:\n                    median_val = df_copy[col].median()\n                    df_copy[col] = df_copy[col].fillna(median_val)\n                    print(f\"  -> 분포가 비대칭(skew={skew:.2f})이므로 중앙값 {median_val}으로 대체\")\n                else:\n                    mean_val = df_copy[col].mean()\n                    df_copy[col] = df_copy[col].fillna(mean_val)\n                    print(f\"  -> 분포가 대칭(skew={skew:.2f})이므로 평균값 {mean_val}으로 대체\")\n            else:\n                mode_val = df_copy[col].mode()[0] if not df_copy[col].mode().empty else \"unknown\"\n                df_copy[col] = df_copy[col].fillna(mode_val)\n                print(f\"  -> 범주형 컬럼이므로 최빈값 '{mode_val}'으로 대체\")\n\n    return df_copy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:46:47.955200Z",
     "start_time": "2025-04-25T17:46:47.949347Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "f4985a3091634866",
   "cell_type": "code",
   "source": "customer_train_df   = handle_missing_values(customer_train_df)\ncredit_train_df      = handle_missing_values(credit_train_df)\nsales_train_df      = handle_missing_values(sales_train_df)\nbilling_train_df    = handle_missing_values(billing_train_df)\nbalance_train_df    = handle_missing_values(balance_train_df)\nchannel_train_df    = handle_missing_values(channel_train_df)\nmarketing_train_df  = handle_missing_values(marketing_train_df)\nperformance_train_df = handle_missing_values(performance_train_df)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:47:55.611781Z",
     "start_time": "2025-04-25T17:46:47.992316Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "8d6cc33ebb1d64c0",
   "cell_type": "code",
   "source": "customer_test_df     = handle_missing_values(customer_test_df)\ncredit_test_df       = handle_missing_values(credit_test_df)\nsales_test_df        = handle_missing_values(sales_test_df)\nbilling_test_df      = handle_missing_values(billing_test_df)\nbalance_test_df      = handle_missing_values(balance_test_df)\nchannel_test_df      = handle_missing_values(channel_test_df)\nmarketing_test_df    = handle_missing_values(marketing_test_df)\nperformance_test_df  = handle_missing_values(performance_test_df)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:48:06.923860Z",
     "start_time": "2025-04-25T17:47:55.703788Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "1ea1cb9334efc073",
   "cell_type": "markdown",
   "source": "# 라벨 인코딩 처리",
   "metadata": {}
  },
  {
   "id": "baed85b5d52f6880",
   "cell_type": "code",
   "source": "from sklearn.preprocessing import LabelEncoder",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:48:07.516500Z",
     "start_time": "2025-04-25T17:48:06.976663Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "cd82773680b2ea28",
   "cell_type": "code",
   "source": "def label_encode_dataframe(df, exclude_cols=None):\n    # 원본 데이터프레임을 수정하지 않기 위해 복사\n    df_encoded = df.copy()\n\n    # 제외할 컬럼 목록 설정\n    if exclude_cols is None:\n        exclude_cols = []\n\n    # object 타입 컬럼 찾기\n    object_columns = df_encoded.select_dtypes(include=['object']).columns\n\n    # 인코딩할 컬럼 (제외 컬럼 제외)\n    encode_columns = [col for col in object_columns if col not in exclude_cols]\n\n    if len(encode_columns) == 0:\n        print(\"인코딩할 object 타입 컬럼이 없습니다.\")\n        return df_encoded\n\n    print(f\"총 {len(encode_columns)}개의 object 타입 컬럼에 라벨 인코딩을 적용합니다.\")\n\n    # 각 컬럼에 라벨 인코딩 적용\n    for col in encode_columns:\n        print(f\"컬럼 '{col}' 인코딩 중...\")\n\n        # 해당 컬럼의 유니크 값 수 확인\n        unique_count = df_encoded[col].nunique()\n        print(f\"  -> 유니크 값 수: {unique_count}\")\n\n        # 누락된 값이 있는지 확인\n        null_count = df_encoded[col].isnull().sum()\n        if null_count > 0:\n            print(f\"  -> 주의: {null_count}개의 결측치가 있습니다.\")\n\n        # 라벨 인코더 생성 및 적용\n        le = LabelEncoder()\n\n        # 결측치가 있는 경우 임시로 처리 (인코딩 후 다시 NaN으로 변경)\n        temp_col = df_encoded[col].copy()\n        mask_null = temp_col.isnull()\n\n        if mask_null.any():\n            # 결측치는 임시로 특수 문자열로 대체\n            temp_col = temp_col.fillna('NULL_VALUE_FOR_ENCODING')\n\n        # 인코딩 적용\n        temp_col = le.fit_transform(temp_col.astype(str))\n\n        # 인코딩된 값 데이터프레임에 대입\n        df_encoded[col] = temp_col\n\n        # 결측치가 있었다면 다시 NaN으로 변경\n        if mask_null.any():\n            df_encoded.loc[mask_null, col] = np.nan\n\n        print(f\"  -> 인코딩 완료: {len(le.classes_)}개의 클래스로 변환\")\n\n    print(\"모든 컬럼 인코딩 완료!\")\n    return df_encoded  # 인코딩된 데이터프레임만 반환",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:48:07.523126Z",
     "start_time": "2025-04-25T17:48:07.519140Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "71f9045dd7ba64d1",
   "cell_type": "code",
   "source": "exclude_columns = ['ID', 'Segment']\n\ncustomer_train_df   = label_encode_dataframe(customer_train_df, exclude_columns)\ncredit_train_df = label_encode_dataframe(credit_train_df, exclude_columns)\nsales_train_df = label_encode_dataframe(sales_train_df, exclude_columns)\nbilling_train_df = label_encode_dataframe(billing_train_df, exclude_columns)\nchannel_train_df = label_encode_dataframe(channel_train_df, exclude_columns)\nmarketing_train_df = label_encode_dataframe(marketing_train_df, exclude_columns)\nperformance_train_df = label_encode_dataframe(performance_train_df, exclude_columns)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:48:33.468641Z",
     "start_time": "2025-04-25T17:48:07.566895Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "f94c6339a61009c6",
   "cell_type": "code",
   "source": "exclude_columns = ['ID']\n\ncustomer_test_df   = label_encode_dataframe(customer_test_df, exclude_columns)\ncredit_test_df     = label_encode_dataframe(credit_test_df, exclude_columns)\nsales_test_df      = label_encode_dataframe(sales_test_df, exclude_columns)\nbilling_test_df    = label_encode_dataframe(billing_test_df, exclude_columns)\nchannel_test_df    = label_encode_dataframe(channel_test_df, exclude_columns)\nmarketing_test_df  = label_encode_dataframe(marketing_test_df, exclude_columns)\nperformance_test_df= label_encode_dataframe(performance_test_df, exclude_columns)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:48:39.106120Z",
     "start_time": "2025-04-25T17:48:33.555862Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "f02608a4c2f617c9",
   "cell_type": "code",
   "source": "customer_test_df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:48:39.208037Z",
     "start_time": "2025-04-25T17:48:39.127541Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "4ce68f0de7e7aca6",
   "cell_type": "code",
   "source": "# 기본 데이터프레임 설정\nmerged_train_df = customer_train_df.copy()\n\n# 나머지 데이터프레임들을 병합\nfor df_name in ['credit_train_df', 'sales_train_df', 'billing_train_df',\n                'channel_train_df', 'marketing_train_df', 'performance_train_df']:\n    print(f\"{df_name} 병합 중...\")\n    # '기준년월'과 'ID' 모두를 기준으로 병합\n    merged_train_df = merged_train_df.merge(globals()[df_name], on=['기준년월', 'ID'], how='left')\n    print(f\"현재 병합된 데이터프레임 크기: {merged_train_df.shape}\")\n    del globals()[df_name]\n    gc.collect()",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:49:32.568663Z",
     "start_time": "2025-04-25T17:48:39.249377Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "3f757e4ea6a9fcd4",
   "cell_type": "code",
   "source": "merged_test_df = customer_test_df.copy()\n\n# 나머지 데이터프레임들을 병합\nfor df_name in ['credit_test_df', 'sales_test_df', 'billing_test_df',\n                'channel_test_df', 'marketing_test_df', 'performance_test_df']:\n    print(f\"{df_name} 병합 중...\")\n    # '기준년월'과 'ID' 모두를 기준으로 병합\n    merged_test_df = merged_test_df.merge(globals()[df_name], on=['기준년월', 'ID'], how='left')\n    print(f\"현재 병합된 데이터프레임 크기: {merged_test_df.shape}\")\n    del globals()[df_name]\n    gc.collect()",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:50:49.830364Z",
     "start_time": "2025-04-25T17:50:35.564142Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "1cee4f8bd2249735",
   "cell_type": "code",
   "source": "import xgboost as xgb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:51:25.434756Z",
     "start_time": "2025-04-25T17:51:25.354228Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "7d9468504cbb5501",
   "cell_type": "code",
   "source": "feature_cols = [col for col in merged_train_df.columns if col not in [\"ID\", \"Segment\"]]\n\nX = merged_train_df[feature_cols].copy()\ny = merged_train_df[\"Segment\"].copy()\n\nle_target = LabelEncoder()\ny_encoded = le_target.fit_transform(y)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:53:35.324872Z",
     "start_time": "2025-04-25T17:53:20.132690Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "ed5de859-827d-4d3a-8356-5fe7732db933",
   "cell_type": "code",
   "source": "X_test = merged_test_df[feature_cols].copy()",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "6a4e2937-9e4c-49fd-9c4a-1071d4008ba9",
   "cell_type": "code",
   "source": "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\nfor col in categorical_features:\n    # 결측치 채우기 (있는 경우)\n    if X[col].isnull().any():\n        X[col] = X[col].fillna('-999')\n    if X_test[col].isnull().any():\n        X_test[col] = X_test[col].fillna('-999')\n    \n    # 테스트 데이터에 없는 값이 있으면 처리\n    all_values = set(X[col].unique()) | set(X_test[col].unique())\n    label_map = {val: idx for idx, val in enumerate(all_values)}\n    \n    X[col] = X[col].map(label_map)\n    X_test[col] = X_test[col].map(label_map)",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "7b9a348f-0f77-4d30-9e52-cc583c90b3bd",
   "cell_type": "code",
   "source": "gc.collect()",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "160870632a280e68",
   "cell_type": "markdown",
   "source": "# 학습",
   "metadata": {}
  },
  {
   "id": "91588610f06743ed",
   "cell_type": "code",
   "source": "try:\n    model = xgb.XGBClassifier(\n        tree_method='gpu_hist',  # GPU 모드 설정\n        gpu_id=0,\n        n_estimators=200,\n        learning_rate=0.1,\n        max_depth=6,\n        subsample=0.8,\n        colsample_bytree=0.8,\n        random_state=42\n    )\n    print(\"GPU 사용 가능: gpu_hist 모드 적용\")\n    model.fit(X, y_encoded)\nexcept Exception:\n    model = xgb.XGBClassifier(\n        n_estimators=200,\n        learning_rate=0.1,\n        max_depth=6,\n        subsample=0.8,\n        colsample_bytree=0.8,\n        random_state=42\n    )\n    print(\"GPU 사용 불가: CPU 모드 적용\")\n    model.fit(X, y_encoded)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:57:56.026640Z",
     "start_time": "2025-04-25T17:56:23.136297Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "ba1a8611-f489-429f-b1cf-df7ce209910d",
   "cell_type": "code",
   "source": "y_test_pred = model.predict(X_test)",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "aa375fb1-a33f-4d23-9841-778c890f5643",
   "cell_type": "code",
   "source": "y_test_pred_labels = le_target.inverse_transform(y_test_pred)",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "2e3e58a6-a0bb-43cb-abba-d4179995e632",
   "cell_type": "code",
   "source": "# 예측 결과를 테스트 데이터에 추가\ntest_data = merged_test_df[[\"ID\"]].copy()\ntest_data[\"pred_label\"] = y_test_pred_labels",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "c8e79423-9730-4897-9988-afd283f7ce79",
   "cell_type": "code",
   "source": "# ID별로 가장 많이 예측된 세그먼트 선택\nsubmission = test_data.groupby(\"ID\")[\"pred_label\"] \\\n             .agg(lambda x: x.value_counts().idxmax()) \\\n             .reset_index()\nsubmission.columns = [\"ID\", \"Segment\"]",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "59552c8c-3095-432c-8b4d-d2b68efad292",
   "cell_type": "code",
   "source": "# 결과 저장\nsubmission.to_csv('./submission.csv', index=False)\nprint(\"예측 완료! 제출 파일이 생성되었습니다.\")",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "ccc7c76d-6c2c-4d8d-8b7c-2c84affa5f0d",
   "cell_type": "code",
   "source": "# 성능 지표 확인 (상위 20개 중요 특성)\nif hasattr(model, 'feature_importances_'):\n    feature_importance = pd.Series(model.feature_importances_, index=X.columns)\n    top_features = feature_importance.nlargest(20)\n    print(\"\\n상위 20개 중요 특성:\")\n    print(top_features)",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
